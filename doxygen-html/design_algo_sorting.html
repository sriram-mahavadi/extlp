<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>ExtLP: Parallel Disk Sorting</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>

</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">ExtLP
   &#160;<span id="projectnumber">1.0-dev</span>
   </div>
   
  </td>
  
  
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.7.6.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="dynsections.js"></script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div>
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
  initNavTree('design_algo_sorting.html','');
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Parallel Disk Sorting </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><dl class="author"><dt><b>Author:</b></dt><dd>Roman Dementiev (2006)</dd></dl>
<p>The development of STXXL has been started with sorting, because it is <code>the</code> fundamental tool for I/O-efficient processing of large data sets. Therefore, an efficient implementation of sorting largely defines the performance of an external memory software library as a whole. To achieve the best performance our implementation <a class="el" href="citelist.html#CITEREF_DemSan03">DemSan03</a> uses parallel disks, has an optimal I/O volume <img class="formulaInl" alt="$ \mathcal{O}(\frac{N}{DB}\log_{M/B}\frac{N}{B}) $" src="form_29.png"/> (that matches the lower bound), and guarantees almost perfect overlap between I/O and computation.</p>
<p>No previous implementation has all these properties, which are needed for a good practical sorting. LEDA-SM <a class="el" href="citelist.html#CITEREF_CraMeh99">CraMeh99</a> and TPIE <a class="el" href="citelist.html#CITEREF_APV02">APV02</a> concentrate on single disk implementations. For the overlapping of I/O and computation they rely on prefetching and caching provided by the operating system, which is suboptimal since the system knows little about the application's access pattern.</p>
<p>Barve and Vitter implemented a parallel disk algorithm <a class="el" href="citelist.html#CITEREF_BarGroVit97">BarGroVit97</a> that can be viewed as the immediate ancestor of our algorithm. Innovations with respect to our sorting are: A different allocation strategy that enables better theoretical I/O bounds <a class="el" href="citelist.html#CITEREF_HutSanVit01b">HutSanVit01b</a> <a class="el" href="citelist.html#CITEREF_KalVar01">KalVar01</a>; a prefetching algorithm that optimizes the number of I/O steps and never evicts data previously fetched; overlapping of I/O and computation; a completely asynchronous implementation that reacts flexibly to fluctuations in disk speeds; and an implementation that sorts many GBytes and does not have to limit internal memory size artificially to obtain a nontrivial number of runs. Additionally, our implementation is not a prototype, it has a generic interface and is a part of the software library STXXL.</p>
<p>Algorithms in <a class="el" href="citelist.html#CITEREF_Raj98">Raj98</a> <a class="el" href="citelist.html#CITEREF_ChaCor02">ChaCor02</a> <a class="el" href="citelist.html#CITEREF_ChaCorWis01">ChaCorWis01</a> have the theoretical advantage of being deterministic. However, they need three passes over data even for not too large inputs.</p>
<p>Prefetch buffers for disk load balancing and overlapping of I/O and computation have been intensively studied for external memory merge sort ( <a class="el" href="citelist.html#CITEREF_PaiVar92">PaiVar92</a> <a class="el" href="citelist.html#CITEREF_CaoFelKarLi96">CaoFelKarLi96</a> <a class="el" href="citelist.html#CITEREF_AlbGarLeo98">AlbGarLeo98</a> <a class="el" href="citelist.html#CITEREF_HutSanVit01b">HutSanVit01b</a> <a class="el" href="citelist.html#CITEREF_KalVar01">KalVar01</a> <a class="el" href="citelist.html#CITEREF_KimKar00">KimKar00</a>). But we have not seen results that guarantee overlapping of I/O and computation during the parallel disk merging of arbitrary runs.</p>
<p>There are many good practical implementations of sorting (e.g. <a class="el" href="citelist.html#CITEREF_NBCGL94">NBCGL94</a> <a class="el" href="citelist.html#CITEREF_Aga96">Aga96</a> <a class="el" href="citelist.html#CITEREF_NKG00">NKG00</a> <a class="el" href="citelist.html#CITEREF_Wyl99">Wyl99</a>) that address parallel disks, overlapping of I/O and computation, and have a low internal overhead. However, we are not aware of fast implementations that give theoretical performance guarantees on achieving asymptotically optimal I/O. Most practical implementations use a form of striping that requires <img class="formulaInl" alt="$ \Omega(\frac{N}{DB}\log_{\Theta(\frac{M}{DB})}\frac{N}{B}) $" src="form_30.png"/> I/Os rather than the optimal <img class="formulaInl" alt="$ \Theta(\frac{N}{DB}\log_{\Theta(M/B)}\frac{N}{B}) $" src="form_31.png"/>. This difference is usually considered insignificant for practical purposes. However, already on our experimental system we have to go somewhat below the block sizes that give the best performance if the input size is 128~GBytes. Another reduction of the block size by a factor of eight (we have eight disks) could increase the run time significantly. We are also not aware of high performance implementations that guarantee overlap of I/O and computation during merging for inputs such as the one described in <a class="el" href="design_algo_sorting.html#design_algo_sorting_merging">Overlapping I/O and Merging</a>.</p>
<p>On the other hand, many of the practical merits of our implementation are at least comparable with the best current implementations: We are close to the peak performance of our system.</p>
<h2><a class="anchor" id="design_algo_sorting_overlapping"></a>
Multi-way Merge Sort with Overlapped I/Os</h2>
<p>Perhaps the most widely used external memory sorting algorithm is <em>k</em>-way merge sort: During <b>run formation</b>, chunks of <img class="formulaInl" alt="$ \Theta(M) $" src="form_32.png"/> elements are read, sorted internally, and written back to the disk as sorted <em>runs</em>. The runs are then merged into larger runs until only a single run is left. <img class="formulaInl" alt="$ k = \mathcal{O}(M/B) $" src="form_33.png"/> runs can be sorted in a single pass by keeping up to <em>B</em> of the smallest elements of each run in internal memory. Using randomization, prediction of the order in which blocks are accessed, a prefetch buffer of <img class="formulaInl" alt="$ \mathcal{O}(D) $" src="form_34.png"/> blocks, and an optimal prefetching strategy, it is possible to implement <em>k</em>-way merging using <em>D</em> disks in a load balanced way <a class="el" href="citelist.html#CITEREF_HutSanVit01b">HutSanVit01b</a>. However, the rate at which new blocks are requested is more difficult to predict so that this algorithm does not guarantee overlapping of I/O and computation. In this section, we derive a parallel disk algorithm that compensates these fluctuations in the block request rate by a FIFO buffer of <img class="formulaInl" alt="$ k+\Theta(D) $" src="form_35.png"/> blocks.</p>
<h3><a class="anchor" id="design_algo_sorting_runform"></a>
Run Formation</h3>
<p>There are many ways to overlap I/O and run formation. We start with a very simple method that treats internal sorting as a black box and therefore can use the fastest available internal sorters. Two threads cooperate to build <em>k</em> runs of size <img class="formulaInl" alt="$ M/2 $" src="form_36.png"/>:</p>
<div class="fragment"><pre class="fragment">
post a read request for runs 1 and 2
thread A:                | thread B:
for r:=1 to k do         | for r:=1 to k-2 do
  wait until             |   wait until
    run r is read        |     run r is written
  sort run r             |   post a read for run r+2
  post a write for run r |
</pre></div><div class="image">
<img src="overlapping_runformation_small.png" alt="overlapping_runformation_small.png"/>
<div class="caption">
Overlapping I/O and computation during run formation.</div></div>
<p> The figure above illustrates how I/O and computation is overlapped by this algorithm. Formalizing this figure, we can prove that using this approach an input of size <em>N</em> can be transformed into sorted runs of size <img class="formulaInl" alt="$ M/2 - \mathcal{O}(DB) $" src="form_37.png"/> in time <img class="formulaInl" alt="$ \max(2T_{\mathrm{sort}}(M/2)N/M,\frac{2LN}{DB}) + \mathcal{O}(\frac{LM}{DB}) $" src="form_38.png"/>, where <img class="formulaInl" alt="$ T_{\mathrm{sort}}(x) $" src="form_39.png"/> denotes the time for sorting <em>x</em> elements internally and where <em>L</em> is the time needed for a parallel I/O step.</p>
<p>In <a class="el" href="citelist.html#CITEREF_DemSan03">DemSan03</a> one can find an algorithm which generates longer runs of average length <img class="formulaInl" alt="$ 2M $" src="form_40.png"/> and overlaps I/O and computation.</p>
<h3><a class="anchor" id="design_algo_sorting_multiway"></a>
Multi-way Merging</h3>
<p>We want to merge <em>k</em> sorted sequences comprising <em>N'</em> elements stored in <img class="formulaInl" alt="$ N'/B $" src="form_41.png"/> blocks (In practical situations, where a single merging phase suffices, we will have <img class="formulaInl" alt="$ N'=N $" src="form_42.png"/>). In each iteration, the merging thread chooses the smallest remaining element from the <em>k</em> sequences and hands it over to the I/O thread. Prediction of read operations is based on the observation that the merging thread does not need to access a block until its smallest element becomes the smallest unread element. We therefore record the <b>smallest</b> keys of each block during run formation. By merging the resulting <em>k</em> sequences of smallest elements, we can produce a sequence <img class="formulaInl" alt="$ \sigma $" src="form_43.png"/> of block identifiers that indicates the exact order in which blocks are logically read by the merging thread. The overhead for producing and storing the prediction data structure is negligible because its size is a factor at least <em>B</em> smaller than the input.</p>
<p>The prediction sequence <img class="formulaInl" alt="$ \sigma $" src="form_43.png"/> is used as follows. The merging thread maintains the invariant that it always buffers the <em>k</em> first blocks in <img class="formulaInl" alt="$ \sigma $" src="form_43.png"/> that contain unselected elements, i.e., initially, the first <em>k</em> blocks from <img class="formulaInl" alt="$ \sigma $" src="form_43.png"/> are read into these <b>merge buffers</b>. When the last element of a merge buffer block is selected, the now empty buffer frame is returned to the I/O thread and the next block in <img class="formulaInl" alt="$ \sigma $" src="form_43.png"/> is read.</p>
<p>The keys of the smallest elements in each buffer block are kept in a tournament tree data structure <a class="el" href="citelist.html#CITEREF_Knu98">Knu98</a> so that the currently smallest element can be selected in time <img class="formulaInl" alt="$ \mathcal{O}(\log k) $" src="form_44.png"/>. Hence, the total internal work for merging is <img class="formulaInl" alt="$ \mathcal{O}(N'\log k) $" src="form_45.png"/>.</p>
<p>We have now defined multi-way merging from the point of view of the sorting algorithm. Our approach to merging slightly deviates from previous approaches that keep track of the run numbers of the merge blocks and pre-assign each merge block to the corresponding input sequence. In these approaches also the <b>last</b> key in the <b>previous</b> block decides about the position of a block in <img class="formulaInl" alt="$ \sigma $" src="form_43.png"/>. The correctness of our approach is shown in <a class="el" href="citelist.html#CITEREF_DemSan03">DemSan03</a>. With respect to performance, both approaches should be similar. Our approach is somewhat simpler, however --- note that the merging thread does not need to know anything about the <em>k</em> input runs and how they are allocated. Its only input is the prediction sequence <img class="formulaInl" alt="$ \sigma $" src="form_43.png"/>. In a sense, we are merging individual blocks and the order in <img class="formulaInl" alt="$ \sigma $" src="form_43.png"/> makes sure that the overall effect is that the input runs are merged. A conceptual advantage is that data <b>within</b> a block decides about when a block is read.</p>
<h3><a class="anchor" id="design_algo_sorting_merging"></a>
Overlapping I/O and Merging</h3>
<div class="image">
<img src="overlapping_merging_small.png" alt="overlapping_merging_small.png"/>
<div class="caption">
Data flow of overlapped parallel disk multi-way merging.</div></div>
<p> Although we can predict the order in which blocks are read, we cannot easily predict how much internal work is done between two reads. For example, consider <em>k</em> identical runs storing the sequence <img class="formulaInl" alt="$ \fboxsep0.5mm\framebox{$1^{B-1}2$}\framebox{$3^{B-1}4$}\framebox{$5^{B-1}6$} \cdots $" src="form_46.png"/>. After initializing the merge buffers, the merging thread will consume <img class="formulaInl" alt="$ k(B-1) $" src="form_47.png"/> values '1' before it posts another read. Then it will post one read after selecting each of the next <em>k</em> values (2). Then there will be a pause of another <img class="formulaInl" alt="$ k(B-1) $" src="form_47.png"/> steps and another <em>k</em> reads are following each other quickly, etc. We explain how to overlap I/O and computation despite this irregularity using the I/O model of Aggarwal and Vitter <a class="el" href="citelist.html#CITEREF_AggVit88">AggVit88</a> that allows access to <em>D</em> <b>arbitrary</b> blocks within one I/O step. To model overlapping of I/O and computation, we assume that an I/O step takes time <em>L</em> and can be done in parallel with internal computations. We maintain an <b>overlap buffer</b> that stores up to <img class="formulaInl" alt="$ k+3D $" src="form_48.png"/> blocks in a FIFO manner (see figure above). Whenever the overlap buffer is non-empty, a read can be served from it without blocking. Writing is implemented using a <b>write buffer</b> FIFO with <img class="formulaInl" alt="$ 2DB $" src="form_49.png"/> elements capacity. An <b>I/O thread</b> inputs or outputs <em>D</em> blocks in time <em>L</em> using the following strategy: Whenever no I/O is active and at least <img class="formulaInl" alt="$ DB $" src="form_50.png"/> elements are present in the write buffer, an output step is started. When no I/O is active, less than <em>D</em> output blocks are available, and at least <em>D</em> overlap buffers are unused, then the next <em>D</em> blocks from <img class="formulaInl" alt="$ \sigma $" src="form_43.png"/> are fetched into the overlap buffer. This strategy guarantees that merging <em>k</em> sorted sequences with a total of <em>N'</em> elements can be implemented to run in time <img class="formulaInl" alt="$ \max\left(\frac{2LN'}{DB}, \ell N'\right)+\mathcal{O}(L\lceil\frac{k}{D}\rceil) $" src="form_51.png"/> where <img class="formulaInl" alt="$ \ell $" src="form_52.png"/> is the time needed by the merging thread to produce one element of output and <em>L</em> is the time needed to input or output <em>D</em> arbitrary blocks <a class="el" href="citelist.html#CITEREF_DemSan03">DemSan03</a>.</p>
<h3><a class="anchor" id="design_algo_sorting_scheduling"></a>
Disk Scheduling</h3>
<p>The I/Os for the run formation and for the output of merging are perfectly balanced over all disks if all sequences are <b>striped</b> over the disks, i.e., sequences are stored in blocks of <em>B</em> elements each and the blocks numbered <img class="formulaInl" alt="$ i,\ldots,i+D-1 $" src="form_53.png"/> in a sequence are stored on different disks for all <em>i</em>. In particular, the original input and the final output of sorting can use any kind of striping.</p>
<p>The merging algorithm presented above is optimal for the unrealistic model of Aggarwal and Vitter <a class="el" href="citelist.html#CITEREF_AggVit88">AggVit88</a> which allows to access any <em>D</em> blocks in an I/O step. This facilitates good performance for fetching very irregularly placed input blocks. However, this model can be simulated using <em>D</em> independent disks using <b>randomized striping allocation</b> <a class="el" href="citelist.html#CITEREF_VitHut01">VitHut01</a> and a prefetch buffer of size <img class="formulaInl" alt="$ m = \Theta(D) $" src="form_54.png"/> blocks: In almost every input step, <img class="formulaInl" alt="$ (1-\mathcal{O}(D/m))D $" src="form_55.png"/> blocks from prefetch sequence <img class="formulaInl" alt="$ \sigma $" src="form_43.png"/> can be fetched <a class="el" href="citelist.html#CITEREF_DemSan03">DemSan03</a>.</p>
<h2><a class="anchor" id="design_algo_sorting_impl"></a>
Implementation Details</h2>
<p><b>Run Formation.</b> We build runs of a size close to <img class="formulaInl" alt="$ M/2 $" src="form_36.png"/> but there are some differences to the simple algorithm from <a class="el" href="design_algo_sorting.html#design_algo_sorting_runform">Run Formation</a>. Overlapping of I/O and computation is achieved using the call-back mechanism supported by the I/O layer. Thus, the sorter remains portable over different operating systems with different interfaces to threading.</p>
<p>We have two implementations with respect to the internal work: stxxl::sort is a comparison based sorting using std::sort from STL to sort the runs internally; stxxl::ksort exploits integer keys and has smaller internal memory bandwidth requirements for large elements with small key fields. After reading elements using DMA (i.e. the STXXL direct access), we extract pairs <img class="formulaInl" alt="$ (\mathrm{key},\mathrm{pointerToElement}) $" src="form_56.png"/>, sort these pairs, and only then move elements in sorted order to write buffers from where they are output using DMA.</p>
<p>Furthermore, we exploit random keys. We use two passes of MSD (most significant digit) radix sort of the key-pointer pairs. The first pass uses the <em>m</em> most significant bits where <em>m</em> is a tuning parameter depending on the size of the processor caches and of the TLB (translation look-aside buffer). This pass consists of a counting phase that determines bucket sizes and a distribution phase that moves pairs. The counting phase is fused into a single loop with pair extraction. The second pass of radix sort uses a number of bits that brings us closest to an expected bucket size of two. This two-pass algorithm is much more cache efficient than a one-pass radix sort. (On our system we get a factor of 3.8 speedup over the one pass radix sort and a factor of 1.6 over STL's sort which in turn is faster than a hand tuned quicksort (for sorting <img class="formulaInl" alt="$ 2^{21} $" src="form_57.png"/> pairs storing a random four byte key and a pointer). The remaining buckets are sorted using a comparison based algorithm: Optimal straight line code for <img class="formulaInl" alt="$ n \leq 4 $" src="form_58.png"/>, insertion sort for <img class="formulaInl" alt="$ n \in \{ 5..16 \} $" src="form_59.png"/>, and quicksort for <img class="formulaInl" alt="$ n > 16 $" src="form_60.png"/>.</p>
<p><b>Multi-way Merging.</b> We have adapted the tuned multi-way merger from <a class="el" href="citelist.html#CITEREF_San00b">San00b</a>, i.e. a tournament tree stores pointers to the current elements of each merge buffer.</p>
<p><b>Overlapping I/O and Computation.</b> We integrate the prefetch buffer and the overlap buffer to a <b>read buffer</b>. We distribute the buffer space between the two purposes of minimizing disk idle time and overlapping I/O and computation indirectly by computing an optimal prefetch sequence for a smaller buffer space.</p>
<p><b>Asynchronous I/O.</b> I/O is performed without any synchronization between the disks. The prefetcher computes a sequence <img class="formulaInl" alt="$ \sigma' $" src="form_61.png"/> of blocks indicating the order in which blocks should be fetched. As soon as a buffer block becomes available for prefetching, it is used to generate an asynchronous read request for the next block in <img class="formulaInl" alt="$ \sigma' $" src="form_61.png"/>. The I/O layer of STXXL queues this request at the disk storing the block to be fetched. The thread for this disk serves the queued request in FIFO manner. All I/O is implemented without superfluous copying. STXXL opens files with the option <code>O_DIRECT</code> so that blocks are directly moved by DMA (direct memory access) to user memory. A fetched block then travels to the prefetch/overlap buffer and from there to a merge buffer simply by passing a pointer. Similarly, when an element is merged, it is directly moved from the merge buffer to the write buffer and a block of the write buffer is passed to the output queue of a disk simply by passing a pointer to the the I/O layer of STXXL that then uses <code>write</code> to output the data using DMA. </p>
</div></div><!-- contents -->
</div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Defines</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

  <div id="nav-path" class="navpath">
    <ul>
      <li class="navelem"><a class="el" href="design.html">Design of STXXL</a>      </li>
      <li class="navelem"><a class="el" href="design_stl.html">The STL-User Layer</a>      </li>
      <li class="navelem"><a class="el" href="design_stl_algo.html">STXXL Algorithms</a>      </li>

    <li class="footer">Generated on Sat Jun 14 2014 01:55:17 for ExtLP by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.6.1 </li>
   </ul>
 </div>


</body>
</html>
